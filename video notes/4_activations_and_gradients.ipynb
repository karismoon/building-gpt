{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70dd435d",
   "metadata": {},
   "source": [
    "# [Activations & Gradients, BatchNorm](https://youtu.be/P6sfmUTpUmc?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)\n",
    "Karis, 12/8  \n",
    "Video is walking through [this code](https://github.com/karpathy/nn-zero-to-hero/blob/master/lectures/makemore/makemore_part3_bn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046dac42",
   "metadata": {},
   "source": [
    "### fixing initial loss\n",
    "\n",
    "At initialization, you can generally calculate what loss you predict you will get. \n",
    "\n",
    "In this example, there are always 27 characters that can come next. In initialization, these should all have about equal probability of occurring, or 1/27. Then we can find the negative log probability of this, which is the loss we can expect (about 3.3).  \n",
    "We can achieve this by initializing all logits at the same value. \n",
    "- If the logits take on extreme values (further away from 0), this means that they are very confident in their values/probabilities. However, if they are confidently incorrect this increases the loss by a lot.\n",
    "- We achieve this by initializing all the weights as very small numbers and the biases as 0, so the logits that are multiplied by the weight and added to the bias are close to 0\n",
    "    - You do not want to set weight to 0 though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77672a1d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### fixing saturated tanh\n",
    "\n",
    "outputs of the tanh layer are mostly -1 and 1  \n",
    "This is bad because backpropagation through tanh layers is a formula where values of -1 and 1 make the gradient of that node be 0, killing the gradient  \n",
    "dead neuron - doesn't learn for any input values\n",
    "- can happen during initialization - weights & biases are just set so that the neuron is never used\n",
    "- also can happen during training, if you overtrain and the gradient becomes so high that neuron is never passed through/changed\n",
    "\n",
    "if your initialization is bad enough, a big network will just stop learning at some point"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
